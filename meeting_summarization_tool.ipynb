{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch librosa pydub google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client #Install all the required libraries"
      ],
      "metadata": {
        "id": "mKENbXA38idU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()# Now choose your .json file and click upload"
      ],
      "metadata": {
        "id": "dpVFtXRU921O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.oauth2 import service_account #Authenticate your service account which you have created\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "SERVICE_ACCOUNT_FILE = \"meeting-summarization-tool-00e383a89444.json\"\n",
        "SCOPES = [\"https://www.googleapis.com/auth/drive\"]\n",
        "\n",
        "creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "drive_service = build(\"drive\", \"v3\", credentials=creds)\n",
        "print(\"Successfully authenticated google drive API\") #Your API should be successfully authenticated"
      ],
      "metadata": {
        "id": "4zxuQdL-9724"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "import textwrap\n",
        "from pydub import AudioSegment\n",
        "from google.colab import files\n",
        "from transformers import pipeline, WhisperProcessor, WhisperForConditionalGeneration\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "# Create necessary folders/directories e.g uploads and summaries\n",
        "UPLOAD_FOLDER = '/content/uploaded_files'\n",
        "SUMMARY_FOLDER = '/content/meeting_summaries'\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True) #If the folder already doesn't exist it will be created successfully\n",
        "os.makedirs(SUMMARY_FOLDER, exist_ok=True)#If the folder already doesn't exist it will be created successfully\n",
        "\n",
        "ALLOWED_EXTENSIONS = {'mp3', 'mp4', 'wav'} #The allowed extensions for the upload file.\n",
        "\n",
        "# Set Drive Folder for storage\n",
        "DRIVE_FOLDER_ID = \"1v-rL90zvmXL8_OlRI_gtRcW1wePXTkdV\"  # Make sure to replace your Drive ID\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "def extract_audio(video_path):# Extract audio from the provided input files\n",
        "    try:\n",
        "        video = AudioSegment.from_file(video_path, format=\"mp4\")\n",
        "        audio_path = os.path.join(UPLOAD_FOLDER, 'extracted_audio.wav')\n",
        "        video.export(audio_path, format=\"wav\")\n",
        "        return audio_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting audio: {e}\")\n",
        "        return None\n",
        "\n",
        "def transcribe_audio(audio_path):#Transcribe speech from audo files using Whisper model.\n",
        "    try:\n",
        "        model_id = \"openai/whisper-large-v2\"\n",
        "        processor = WhisperProcessor.from_pretrained(model_id)\n",
        "        model = WhisperForConditionalGeneration.from_pretrained(model_id)\n",
        "\n",
        "        audio, _ = librosa.load(audio_path, sr=16000)\n",
        "        input_features = processor(audio, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
        "        predicted_ids = model.generate(input_features)\n",
        "        transcript = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "        return transcript\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing audio: {e}\")\n",
        "        return None\n",
        "\n",
        "def generate_summary(text):#Generates concise summary\n",
        "    try:\n",
        "        # Use multiple summarization models to improve results\n",
        "        bart_summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "        t5_summarizer = pipeline(\"summarization\", model=\"t5-base\")\n",
        "\n",
        "        # Generate summaries\n",
        "        bart_summary = bart_summarizer(text, max_length=150, min_length=60, do_sample=False)[0]['summary_text']\n",
        "        t5_summary = t5_summarizer(text, max_length=100, min_length=50, do_sample=False)[0]['summary_text']\n",
        "\n",
        "        # Combine results and extract key points\n",
        "        combined_summary = bart_summary + \" \" + t5_summary\n",
        "        summary_lines = combined_summary.split('. ')\n",
        "\n",
        "        # Post-process: convert into actionable bullet points (max 10)\n",
        "        bullet_points = []\n",
        "        for line in summary_lines:\n",
        "            if len(line.strip()) > 0:\n",
        "                bullet_points.append(f\"- {line.strip()}\")\n",
        "\n",
        "        # Ensure a max of 10 bullet points\n",
        "        return \"\\n\".join(bullet_points[:10])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating summary: {e}\")\n",
        "        return None\n",
        "def sentiment_analyze(text):#Perform sentiment analysis\n",
        "    try:\n",
        "        sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "        sentiment = sentiment_pipeline(text)[0]\n",
        "        return f\"Sentiment: {sentiment['label']} (Confidence: {sentiment['score']:.2f})\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error performing sentiment analysis: {e}\")\n",
        "        return None\n",
        "\n",
        "def upload_to_drive(file_path):#Uploading file to the drive.\n",
        "    try:\n",
        "        file_metadata = {\n",
        "            \"name\": os.path.basename(file_path),\n",
        "            \"parents\": [DRIVE_FOLDER_ID]\n",
        "        }\n",
        "        media = MediaFileUpload(file_path, mimetype=\"text/plain\")\n",
        "        file = drive_service.files().create(body=file_metadata, media_body=media, fields=\"id\").execute()\n",
        "        print(f\"File uploaded to Google Drive: {file.get('id')}\")\n",
        "        return file.get(\"id\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading to Drive: {e}\")\n",
        "        return None\n",
        "\n",
        "def download_from_drive(file_id, save_path):#Downloads file from the drive.\n",
        "    try:\n",
        "        request = drive_service.files().get_media(fileId=file_id)\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            f.write(request.execute())\n",
        "        print(f\" File downloaded: {save_path}\")\n",
        "        return save_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading from Drive: {e}\")\n",
        "        return None\n",
        "\n",
        "def save_summary(summary, sentiment, filename):#Saves the summary to the drive folder.\n",
        "    try:\n",
        "        summary_path = os.path.join(SUMMARY_FOLDER, f\"{filename}_summary.txt\")\n",
        "        with open(summary_path, 'w') as file:\n",
        "            file.write(\"=== Meeting Summary ===\\n\")\n",
        "            file.write(summary + \"\\n\\n\")\n",
        "            file.write(\"=== Sentiment Analysis ===\\n\")\n",
        "            file.write(sentiment + \"\\n\")\n",
        "\n",
        "        drive_file_id = upload_to_drive(summary_path)\n",
        "        return drive_file_id\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving summary: {e}\")\n",
        "        return None\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    file_path = os.path.join(UPLOAD_FOLDER, filename)\n",
        "    with open(file_path, 'wb') as f:\n",
        "        f.write(uploaded[filename])\n",
        "    print(f\"File uploaded: {filename}\")\n",
        "\n",
        "    if filename.endswith('.mp4'):\n",
        "        audio_path = extract_audio(file_path)\n",
        "    else:\n",
        "        audio_path = file_path\n",
        "\n",
        "    if audio_path:\n",
        "        transcript = transcribe_audio(audio_path)\n",
        "        if transcript:\n",
        "            summary = generate_summary(transcript)\n",
        "            sentiment = sentiment_analyze(transcript)\n",
        "            if summary and sentiment:\n",
        "                drive_file_id = save_summary(summary, sentiment, filename)\n",
        "                if drive_file_id:\n",
        "                    print(f\"Summary saved & uploaded to Drive: {drive_file_id}\")#The summary would be uploaded to your drive ID.\n",
        "                else:\n",
        "                    print(\"Error saving summary.\")\n",
        "            else:\n",
        "                print(\"Error generating summary or sentiment analysis.\")\n",
        "        else:\n",
        "            print(\"Error transcribing audio.\")\n",
        "    else:\n",
        "        print(\"Error extracting audio.\")"
      ],
      "metadata": {
        "id": "1jHGXRkQ-Yvx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}